author: Umesh Unnikrishnan, Shayak Sen 
id: best-practices-cortex-code-cli 
language: en 
summary: Learn best practices for using Cortex Code CLI, your AI-powered command-line coding agent for building, debugging, and deploying Snowflake applications. 
categories: snowflake-site:taxonomy/solution-center/ai-ml/quickstart
environments: web 
status: Published 

# Best Practices for Cortex Code CLI

This is your guide to Snowflake's **Cortex Code CLI**, an AI-powered command-line coding agent designed to streamline the process of building, debugging, and deploying Snowflake applications through natural language conversations.  

## Installation instructions

``` 
curl -LsS https://ai.snowflake.com/static/cc-scripts/install.sh | sh 
```

### What You'll Need
- Snowflake account with appropriate permissions
- A supported environment: macOS on Apple Silicon, Intel Linux on Intel, or Windows Subsystem for Linux (WSL)
- Terminal access

> **If you're not yet a Snowflake customer** [start your 30-day trial here](https://signup.snowflake.com/cortex-code). 

### What You'll Learn
- Installation requirements
- Key terminology
- 101 use cases (e.g. writing or querying using natural language, creating synthetic datasets and building interactive dashboards.)
- 201 use cases (e.g. building semantic views, Cortex Search services, or Cortex Agents)

## Terminology

- **Cortex Code CLI** is an AI-powered coding agent for building, debugging, and working in Snowflake through natural language conversations.
- **Skills**: specialized workflows within Cortex Code that offer expert guidance for specific, detailed tasks (e.g., creating agents, semantic view debugging).
- **Cortex Agents**: conversational AI assistants you build in Snowflake that can autonomously answer questions, use tools, and interact with your data.
- **Cortex Analyst**: Snowflake service that translates natural language questions into SQL queries, using semantic models to understand business logic.
- **Semantic View**: a Snowflake object that combines data tables with business context (definitions, relationships) to power the queries generated by **Cortex Analyst**.

## Best Practices

### Communicate Naturally

* **Use plain language** to describe what you want, not how to do it  
* **Ask "What steps are available to me?"** if you feel stuck  
* **Check if specialized skills should be loaded** for agents, semantic models, or complex workflows  
* **Iterate conversationally** - just say what you'd like changed

### Review Before Accepting

* **Understand proposed changes** before they're executed, especially SQL DDL/DML operations  
* **Verify file modifications** - what will be created, edited, or deleted  
* **Use caution with production** environments and destructive operations (DROP, DELETE, etc.)  
* **Ask for explanations** if unsure: "Why are you doing this?" or "What will this change?"

### Work Effectively {#work-effectively}

* **Start small and test frequently** - build one component at a time.  
* **Use /plan for complex tasks** to see the full approach before starting  
* **Run Cortex Code in VS Code/Cursor terminal** to view code files side-by-side  
* **Write complex requirements in .md files** and reference them in conversation

### Security & Best Practices

* **Never commit secrets** - keep credentials out of code and version control  
* **Review privilege grants and RBAC changes** carefully  
* **Use skills** like **agent-optimization** or **semantic-view-optimization** for expert workflows  
* **Leverage built-in help** - ask "How does this work?" or check Snowflake documentation


## 101 Use Cases

### Data discovery & querying

Here we'll create a basic synthetic dataset and do some basic analysis to generate a dashboard.

### Connect to a Snowflake account

```
$ cortex -c <your demo account> 
or 
$ cortex 
> connect to <my demo account> 
```

### Discover and Explore Data

Search your data catalog, understand lineage, and find relevant tables.

``` Find all tables related to customers that I have write access to ```

### Ensure you have the right role with the correct permissions

``` What privileges does my role have on this database?```

Diagnose access issues and understand role privileges.

``` Why am I getting a permissions error?```

### Generate Synthetic Data {#generate-synthetic-data}

Some examples below

**Fraud analysis for a fintech company**

```Generate realistic looking synthetic data into <database name>. Create a table of 10000 financial transactions where ~0.5% of them are fraudulent. Include Amount, Location, Merchant, and Time. Make the fraudulent ones look suspicious based on location or amount.```

**Pharma trial data**

```Make a dummy dataset for a clinical trial of a new blood pressure medication. List 100 patients, their age, their dosage group (Placebo vs. 10mg), and their blood pressure readings over 4 weeks.```

**Customer churn data**

```Create a customer churn dataset for a telecom company showing customer usage for 100000 customers. Include basic demographic data such as fake names, phone numbers, US city and state. Also include data usage (GB), call minutes, contract length, and whether they cancelled their service (churn). Ensure there's a customer_id column that's unique. Create the data locally and then upload it to Snowflake.```

### Perform basic queries against this data

Basic example

```Calculate the Churn Rate grouped by state and contract length. Order the results by the highest churn rate first so I can see the most risky regions and contract types ```

``` I want to identify the heaviest data users who are also churning. ```

### Build Interactive Dashboards

Create and deploy Streamlit apps with charts, filters, and interactivity.

Open a good looking dashboard (e.g [dashboard here](https://s3-figma-hubfile-images-production.figma.com/hub/file/carousel/img/fc3a04485c66b47e6985c5bd5f0c4b28495a3456) as an example) and copy it to the clipboard. Paste it into Cortex Code (Ctrl + V). 

``` Build an interactive Streamlit dashboard on this data with state filters and use the conversation so far for examples of the kinds of charts to show. Use the attached image as a template for visuals and branding.```

Once you've verified that the dashboard is working and looks good, you can now upload it to Snowflake. 

```Ensure that the steamlit will work with Snowflake and upload it to Snowflake. Give me a link to access the dashboard when it's done.```

Congratulations! You should now have a working Streamlit dashboard that displays the dataset you created!

## 201 Use Cases

Now, let's make this more interactive by creating a cortex agent to answer questions about this data in Snowflake Intelligence.

In this process, we'll augment the existing synthetic data with some synthetic data of customer calls. 

### Create a Semantic View for Cortex Analyst

Now let's create a semantic view so that you can use Cortex Analyst with this data. Try the prompt below and use the defaults for all the questions it asks. 

```Write a Semantic View named DEMO_TELECOM_CHURN_ANALYTICS for Cortex Analyst based on this data.  Use the semantic-view optimization skill```

### Create a Cortex Search service

First we generate some synthetic data containing customer service calls 

```generate a new table called customer_call_logs. Generate 50 realistic customer service transcripts (2-3 sentences each) as pdf files. Some should be angry complaints about coverage, others should be questions about billing. 

Then use the AI_PARSE_DOCUMENT function to extract the text and layout information from the PDFs into the TRANSCRIPT_TEXT column. Split text into chunks for better search quality. 
``` 

Then let's create a cortex search service that indexes it

```Create a Cortex Search Service named CALL_LOGS_SEARCH that indexes these transcripts. It should index the TRANSCRIPT_TEXT column and filter by CUSTOMER_ID.```

### Create a Cortex Agent

Finally, let's create a Cortex Agent that uses these two services and add it to Snowflake Intelligence

```
Build a Cortex Agent that has access to two tools:
1. cortex_analyst: For querying the TELECOM_CUSTOMERS SQL table.
2. cortex_search: For searching the CALL_LOGS_SEARCH service.
Write a system prompt for this agent.
Persona: You are a Senior Retention Specialist.
Routing Logic: If the user asks for 'metrics', 'counts', or 'averages', use the Analyst tool. If the user asks for 'sentiment', 'reasons', or 'summaries of calls', use the Search tool.
Output Format: Always verify the customer ID before answering. If the risk score is high, end the response with a recommended retention offer (e.g., 'Offer 10% discount').
Constraint: Never reveal the raw CHURN_RISK_SCORE to the user; interpret it as 'Low', 'Medium', or 'High'."
```

### Deploy to Snowflake Intelligence

Finally, we can deploy the agent to [Snowflake Intelligence](https://ai.snowflake.com/)

```Let's deploy this agent to Snowflake Intelligence```

Congrats! You have successfully created and deployed a Snowflake Intelligence agent. 

Now you should be able to access this agent in Snowflake Intelligence and ask it questions like 

*What are customers complaining about in their calls?"* or *"Show me high-risk customers with monthly charges over $100"*

## Conclusion and Resources

The key to success with Cortex Code CLI is to start small, test frequently, and iterate based on feedback. Leverage the built-in skills for complex workflows, always review proposed changes before execution, and use best practices like proper descriptions, verified queries, and custom instructions to ensure your applications are accurate and maintainable.

- [Cortex Code CLI docs](http://docs.snowflake.com/user-guide/cortex-code/cortex-code-cli)
- Start your [30-day Cortex Code Trial](https://signup.snowflake.com/cortex-code)
- [Cortex Code in Snowsight](http://docs.snowflake.com/user-guide/cortex-code/cortex-code-snowsight)

